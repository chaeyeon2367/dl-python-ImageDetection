{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for feasibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "DATASET_PATH = '/Users/shim/dl-python-ImageDetection/dataset/2/'\n",
    "DATASET_OK_PATTERN = '/Users/shim/dl-python-ImageDetection/dataset/2/OK/'\n",
    "DATASET_FAIL_PATTERN = '/Users/shim/dl-python-ImageDetection/2/FAIL/'\n",
    "\n",
    "RESULT_SAVE_PATH = '/Users/shim/dl-python-ImageDetection/dataset/results/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    return Sequential([Conv2D(32, (3,3), activation='relu',input_shape=(256, 256, 1)),\n",
    "                       MaxPool2D(),\n",
    "                       Conv2D(64, (3,3), activation='relu'),\n",
    "                       MaxPool2D(),\n",
    "                       Conv2D(128, (3,3), activation='relu'),\n",
    "                       MaxPool2D(),\n",
    "                       Conv2D(256, (3,3), activation='relu'),\n",
    "                       MaxPool2D(),\n",
    "                       Flatten(),\n",
    "                       Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_name):\n",
    "    img = tf.io.read_file(file_name)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    return tf.image.convert_image_dtype(img, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(directory, extension):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                file_list.append(os.path.join(root, file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_list = get_file_list(DATASET_OK_PATTERN, '.png')\n",
    "ds_ok = tf.data.Dataset.list_files(ok_list)\n",
    "ds_ok_label = tf.data.Dataset.from_tensor_slices([0] * len(ok_list))\n",
    "\n",
    "ds_ok = ds_ok.map(preprocess)\n",
    "ds_ok = tf.data.Dataset.zip((ds_ok, ds_ok_label))\n",
    "\n",
    "fail_list = get_file_list(DATASET_FAIL_PATTERN, '.png')\n",
    "ds_fail = tf.data.Dataset.list_files(fail_list)\n",
    "ds_fail_label = tf.data.Dataset.from_tensor_slices([1] * len(fail_list))\n",
    "\n",
    "ds_fail = ds_fail.map(preprocess)\n",
    "ds_fail = tf.data.Dataset.zip((ds_fail, ds_fail_label))\n",
    "\n",
    "ds = tf.data.Dataset.concatenate(ds_ok, ds_fail)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train, Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_size = len(ok_list) + len(fail_list)\n",
    "train_size = int(ds_size * 0.7)\n",
    "\n",
    "ds = ds.shuffle(ds_size)\n",
    "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).batch(32)\n",
    "ds_validation = ds.skip(train_size).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 33s 2s/step - loss: 0.4148 - accuracy: 0.8640 - val_loss: 0.3171 - val_accuracy: 0.8982\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 34s 2s/step - loss: 0.3465 - accuracy: 0.8776 - val_loss: 0.4191 - val_accuracy: 0.8456\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.3471 - accuracy: 0.8716 - val_loss: 0.3890 - val_accuracy: 0.8737\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.3257 - accuracy: 0.8837 - val_loss: 0.3303 - val_accuracy: 0.8737\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.3479 - accuracy: 0.8565 - val_loss: 0.3635 - val_accuracy: 0.8596\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.3489 - accuracy: 0.8671 - val_loss: 0.2770 - val_accuracy: 0.8947\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.3397 - accuracy: 0.8731 - val_loss: 0.3675 - val_accuracy: 0.8667\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.3301 - accuracy: 0.8807 - val_loss: 0.2755 - val_accuracy: 0.8807\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.3405 - accuracy: 0.8716 - val_loss: 0.3068 - val_accuracy: 0.9018\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.3239 - accuracy: 0.8716 - val_loss: 0.2783 - val_accuracy: 0.8947\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.2960 - accuracy: 0.8852 - val_loss: 0.3751 - val_accuracy: 0.8526\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.3150 - accuracy: 0.8776 - val_loss: 0.2995 - val_accuracy: 0.8842\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.3540 - accuracy: 0.8792 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.3240 - accuracy: 0.8912 - val_loss: 0.3590 - val_accuracy: 0.8561\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.3206 - accuracy: 0.8792 - val_loss: 0.3457 - val_accuracy: 0.8456\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.3374 - accuracy: 0.8640 - val_loss: 0.3791 - val_accuracy: 0.8596\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 40s 2s/step - loss: 0.3234 - accuracy: 0.8686 - val_loss: 0.3072 - val_accuracy: 0.8561\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.3041 - accuracy: 0.8822 - val_loss: 0.2999 - val_accuracy: 0.8737\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.3359 - accuracy: 0.8701 - val_loss: 0.3016 - val_accuracy: 0.8842\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 214s 11s/step - loss: 0.3137 - accuracy: 0.8746 - val_loss: 0.2887 - val_accuracy: 0.8982\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 674s 34s/step - loss: 0.3235 - accuracy: 0.8837 - val_loss: 0.3519 - val_accuracy: 0.8596\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 136s 7s/step - loss: 0.3128 - accuracy: 0.8807 - val_loss: 0.2600 - val_accuracy: 0.8982\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 135s 7s/step - loss: 0.3167 - accuracy: 0.8776 - val_loss: 0.2454 - val_accuracy: 0.9088\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 384s 19s/step - loss: 0.2957 - accuracy: 0.8927 - val_loss: 0.4037 - val_accuracy: 0.8596\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 173s 9s/step - loss: 0.3006 - accuracy: 0.8958 - val_loss: 0.3235 - val_accuracy: 0.8807\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 90s 4s/step - loss: 0.3415 - accuracy: 0.8746 - val_loss: 0.2976 - val_accuracy: 0.8772\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 84s 4s/step - loss: 0.3113 - accuracy: 0.8867 - val_loss: 0.3069 - val_accuracy: 0.8737\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 75s 4s/step - loss: 0.3189 - accuracy: 0.8837 - val_loss: 0.3015 - val_accuracy: 0.8877\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 145s 7s/step - loss: 0.3173 - accuracy: 0.8807 - val_loss: 0.2987 - val_accuracy: 0.8982\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.3142 - accuracy: 0.8852 - val_loss: 0.3040 - val_accuracy: 0.8842\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 83s 4s/step - loss: 0.2920 - accuracy: 0.8776 - val_loss: 0.3035 - val_accuracy: 0.8772\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 588s 29s/step - loss: 0.2959 - accuracy: 0.8867 - val_loss: 0.2808 - val_accuracy: 0.8561\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 145s 7s/step - loss: 0.2773 - accuracy: 0.8807 - val_loss: 0.2939 - val_accuracy: 0.8737\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 47s 2s/step - loss: 0.3107 - accuracy: 0.8640 - val_loss: 0.2751 - val_accuracy: 0.8877\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 92s 5s/step - loss: 0.2570 - accuracy: 0.8958 - val_loss: 0.2581 - val_accuracy: 0.8842\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.2726 - accuracy: 0.9003 - val_loss: 0.2711 - val_accuracy: 0.8877\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.2910 - accuracy: 0.8912 - val_loss: 0.3168 - val_accuracy: 0.8702\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.8958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 15:13:03.655179: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 869 of 947\n",
      "2023-10-19 15:13:03.657471: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 870 of 947\n",
      "2023-10-19 15:13:03.692445: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 377s 3s/step - loss: 0.2508 - accuracy: 0.8958 - val_loss: 0.2925 - val_accuracy: 0.8842\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.2570 - accuracy: 0.8973 - val_loss: 0.2347 - val_accuracy: 0.9088\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 15:14:17.823584: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 829 of 947\n",
      "2023-10-19 15:14:17.883866: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2023-10-19 15:14:17.883906: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 1 of 1024\n",
      "2023-10-19 15:14:17.884682: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 50s 2s/step - loss: 0.2581 - accuracy: 0.9079 - val_loss: 0.2347 - val_accuracy: 0.9053\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 204s 10s/step - loss: 0.2521 - accuracy: 0.9154 - val_loss: 0.1639 - val_accuracy: 0.9439\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 134s 7s/step - loss: 0.2647 - accuracy: 0.8973 - val_loss: 0.2304 - val_accuracy: 0.9088\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 267s 13s/step - loss: 0.2238 - accuracy: 0.9245 - val_loss: 0.2424 - val_accuracy: 0.8912\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 153s 8s/step - loss: 0.2290 - accuracy: 0.9230 - val_loss: 0.2386 - val_accuracy: 0.9018\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 1242s 62s/step - loss: 0.2444 - accuracy: 0.9094 - val_loss: 0.2232 - val_accuracy: 0.9298\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 1615s 81s/step - loss: 0.2544 - accuracy: 0.9048 - val_loss: 0.2829 - val_accuracy: 0.8877\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 75s 4s/step - loss: 0.2471 - accuracy: 0.9033 - val_loss: 0.2104 - val_accuracy: 0.9263\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 284s 14s/step - loss: 0.2434 - accuracy: 0.9079 - val_loss: 0.2322 - val_accuracy: 0.9123\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.2279 - accuracy: 0.9124 - val_loss: 0.2166 - val_accuracy: 0.9333\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.2216 - accuracy: 0.9109 - val_loss: 0.2213 - val_accuracy: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1e60d8a60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, validation_data = ds_validation, epochs=EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 477ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 0s 459ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n"
     ]
    }
   ],
   "source": [
    "def mkdir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.mkdir(path)\n",
    "\n",
    "mkdir(RESULT_SAVE_PATH)\n",
    "mkdir(RESULT_SAVE_PATH + '/TP')\n",
    "mkdir(RESULT_SAVE_PATH + '/TN')\n",
    "mkdir(RESULT_SAVE_PATH + '/FP')\n",
    "mkdir(RESULT_SAVE_PATH + '/FN')\n",
    "\n",
    "index = 0\n",
    "for imgs, labels in ds_validation:\n",
    "    preds = model.predict(imgs)\n",
    "    for idx in range (imgs.shape[0]):\n",
    "        gt = labels[idx].numpy()\n",
    "        y = preds[idx]\n",
    "        if gt == 1 and y > 0.5:\n",
    "            path = RESULT_SAVE_PATH + '/TP'\n",
    "        elif gt == 1 and y <= 0.5:\n",
    "            path = RESULT_SAVE_PATH + '/FN'\n",
    "        elif gt == 0 and y > 0.5:\n",
    "            path = RESULT_SAVE_PATH + '/FP'\n",
    "        else:\n",
    "            path = RESULT_SAVE_PATH + '/TN'\n",
    "        cv2.imwrite(path + '/%.f_%04d.png' % (y, index), imgs[idx].numpy() *255)\n",
    "        index +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
